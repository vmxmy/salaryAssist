import streamlit as st
import pandas as pd
import tempfile
import os
from datetime import datetime
from fiscal_report_full_script import process_sheet, format_excel_with_styles
import json
import matplotlib.pyplot as plt
import numpy as np # ç¡®ä¿å¯¼å…¥ numpy

# --- Matplotlib ä¸­æ–‡æ˜¾ç¤ºè®¾ç½® ---
# ä½¿ç”¨ä»ç³»ç»Ÿä¸­æ‰¾åˆ°çš„å­—ä½“ï¼Œä¼˜å…ˆ Lantinghei SC
plt.rcParams['font.sans-serif'] = ['Lantinghei SC', 'SimSong', 'Kaiti SC', 'Songti SC', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
# --- ç»“æŸè®¾ç½® ---

# --- åˆå§‹åŒ– Session State ---
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []
if 'mapping_data' not in st.session_state:
    st.session_state.mapping_data = None
if 'mapping_valid' not in st.session_state:
    st.session_state.mapping_valid = None # None: æœªä¸Šä¼ , True: æœ‰æ•ˆ, False: æ— æ•ˆ
# --- ç»“æŸåˆå§‹åŒ– ---

# --- æ—¥å¿—è®°å½•å‡½æ•° ---
def log(message, level="INFO"):
    now = datetime.now().strftime("%H:%M:%S")
    level_icon_map = {"INFO": "â„¹ï¸", "WARNING": "âš ï¸", "ERROR": "âŒ", "SUCCESS": "âœ…"}
    icon = level_icon_map.get(level, "â–ªï¸")
    log_level_class = f"log-{level.lower()}"

    # Wrap prefix and message in spans for styling
    formatted_message = f"<span class='log-prefix'>{now} {icon}</span> <span class='{log_level_class}'>{message}</span>"

    st.session_state.log_messages.append(formatted_message)
    # æ³¨æ„ï¼šæ—¥å¿—åœ¨ä¾§è¾¹æ çš„æ›´æ–°é€šå¸¸åœ¨æ•´ä¸ªæŒ‰é’®è„šæœ¬æ‰§è¡Œå®Œåå‘ç”Ÿ
# --- ç»“æŸæ—¥å¿—å‡½æ•° ---

st.set_page_config(layout="wide", page_title="è´¢æ”¿å·¥èµ„å¤„ç†ç³»ç»Ÿ")

# --- NEW CSS for Modern Minimalist Style ---
modern_minimalist_css = """
<style>
/* Import Google Font */
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap');

/* Global Styles */
html, body, [class*="st-"] {{
    font-family: 'Inter', sans-serif;
    background-color: #F8F9FA; /* Light grey background */
    color: #212529; /* Dark text */
}}

/* Sidebar Styles */
[data-testid="stSidebar"] {{
    background-color: #FFFFFF; /* White sidebar */
    border-right: 1px solid #E0E0E0; /* Subtle border */
    box-shadow: 2px 0px 5px rgba(0, 0, 0, 0.05); /* Slight shadow */
}}

/* Titles and Headers */
h1, h2, h3, h4, h5, h6 {{
    font-family: 'Inter', sans-serif;
    font-weight: 600; /* Bolder headers */
}}

/* Custom simple subheader style (replaces old .custom-subheader) */
.simple-subheader {{
    font-size: 1.5em; /* H3 size equivalent */
    font-weight: 600;
    margin-top: 25px;
    margin-bottom: 15px;
    border-bottom: 1px solid #E0E0E0; /* Subtle underline */
    padding-bottom: 8px;
}}

/* Input Controls */
[data-testid="stTextInput"] input,
[data-testid="stDateInput"] input,
[data-testid="stSelectbox"] div[role="combobox"] {{
    border: 1px solid #ced4da;
    border-radius: 0.3rem;
    background-color: #FFFFFF;
}}

/* File Uploader Adjustments */
[data-testid="stFileUploader"] {{
    /* Add some space */
    margin-bottom: 10px;
}}

/* Primary Button Styling */
button[kind="primary"] {{
    background-color: #0d6efd; /* Primary blue */
    color: white;
    padding: 0.75rem 1.25rem; /* Moderate padding */
    font-size: 1rem; /* Standard font size */
    font-weight: 600;
    border-radius: 0.3rem; /* Consistent rounding */
    border: none; /* Remove default border */
    transition: background-color 0.2s ease-in-out; /* Hover effect */
}}

button[kind="primary"]:hover {{
    background-color: #0b5ed7; /* Darker blue on hover */
}}

/* Log Message Styling */
.log-info {{ color: #0dcaf0; }} /* Cyan info */
.log-warning {{ color: #ffc107; }} /* Yellow warning */
.log-error {{ color: #dc3545; font-weight: bold; }} /* Red, bold error */
.log-success {{ color: #198754; }} /* Green success */

/* Styling for the log timestamp and icon */
.log-prefix {{
    color: #6c757d; /* Grey for timestamp/icon */
    margin-right: 5px;
}}

/* Adjust log container in sidebar */
[data-testid="stSidebar"] [data-testid="stExpander"] [data-testid="stVerticalBlock"] {{
     /* Potentially adjust padding or spacing if needed */
}}

</style>
"""
st.markdown(modern_minimalist_css, unsafe_allow_html=True)

# --- æ—§ CSS (æ³¨é‡Šæ‰æˆ–åˆ é™¤) ---
# styled_header_css = """
# <style>
# .custom-subheader {
#     border-left: 5px solid #1E90FF; /* Dodger blue left border */
#     background-color: #F0F8FF; /* Alice blue background */
#     padding: 10px 15px;      /* Padding around text */
#     margin-top: 20px;         /* Space above */
#     margin-bottom: 15px;      /* Space below */
#     border-radius: 5px;       /* Rounded corners */
#     font-size: 1.75em;        /* H3 font size */
#     line-height: 1.4;         /* Adjust line height */
#     font-weight: 600;         /* Make it bolder like headers */
# }
# /* Ensure the text inside aligns well, prevent potential default margins */
# .custom-subheader h3 {
#     margin: 0;
#     padding: 0;
#     line-height: inherit; /* Inherit line height */
#     font-size: inherit; /* Inherit font size */
#     font-weight: inherit; /* Inherit font weight */
# }
#
# /* Target Streamlit's primary button to make it larger */
# button[kind="primary"] {
#     padding: 15px 30px; /* Further increase padding */
#     font-size: 2.4em;  /* Further increase font size */
#     font-weight: bold; /* Ensure font is bold */
# }
# </style>
# """
# st.markdown(styled_header_css, unsafe_allow_html=True)

# --- ä¸»ç•Œé¢ ---
st.title("æˆéƒ½é«˜æ–°åŒºè´¢é‡‘å±€ å·¥èµ„æ¡æ•°æ®å¤„ç†ä¸åˆå¹¶å·¥å…·")

# --- è¡¨å•è¾“å…¥åŒºåŸŸ ---
st.sidebar.header("ğŸ”§ å‚æ•°è®¾ç½®")

# è‡ªå®šä¹‰å•ä½åç§°
unit_name = st.sidebar.text_input("å•ä½åç§°", value="é«˜æ–°åŒºè´¢æ”¿å±€")

# æ—¥æœŸæ§ä»¶ï¼ˆé»˜è®¤å½“å‰æœˆä»½ï¼‰
def_year = datetime.today().year
def_month = datetime.today().month

salary_date = st.sidebar.date_input("å·¥èµ„è¡¨æ—¥æœŸï¼ˆç”¨äºæ ‡é¢˜æ ï¼‰", value=datetime(def_year, def_month, 1), format="YYYY-MM-DD")

# --- æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ ---
with st.sidebar.expander("ğŸ“„ å¤„ç†æ—¥å¿—", expanded=True):
    log_container = st.container(height=300) # å›ºå®šé«˜åº¦å¯æ»šåŠ¨å®¹å™¨
    with log_container:
        for message in st.session_state.log_messages:
            st.markdown(message, unsafe_allow_html=True) # Markdown is now expected to contain spans like <span class='log-info'>...</span>
# --- ç»“æŸæ—¥å¿—æ˜¾ç¤º ---

# æ–‡ä»¶ä¸Šä¼ 
st.markdown("<p class='simple-subheader'>ğŸ“ ä¸Šä¼ æ‰€éœ€æ–‡ä»¶</p>", unsafe_allow_html=True)

col1, col2 = st.columns(2)
with col1:
    # ä½¿ç”¨ markdown ä½œä¸ºæ ‡ç­¾ï¼Œå¹¶éšè— file_uploader è‡ªå¸¦çš„æ ‡ç­¾
    st.caption("ğŸ“ æºæ•°æ®å·¥èµ„è¡¨ï¼ˆæ”¯æŒå¤šæ–‡ä»¶ï¼‰")
    source_files = st.file_uploader("source_uploader", type=["xlsx"], accept_multiple_files=True, label_visibility="collapsed", key="source_uploader")

    st.caption("ğŸ“ å¯¼å‡ºè¡¨å­—æ®µæ¨¡æ¿")
    file_template = st.file_uploader("template_uploader", type=["xlsx"], label_visibility="collapsed", key="template_uploader")

with col2:
    st.caption("ğŸ“ æ‰£æ¬¾é¡¹è¡¨ï¼ˆå«å§“å+å„é¡¹æ‰£æ¬¾ï¼‰")
    file_deductions = st.file_uploader("deductions_uploader", type=["xlsx"], label_visibility="collapsed", key="deductions_uploader")

    st.caption("ğŸ“ å­—æ®µæ˜ å°„è§„åˆ™ ï¼ˆJSONæ ¼å¼ï¼‰")
    file_mapping = st.file_uploader("mapping_uploader", type=["json"], label_visibility="collapsed", key="mapping_uploader")

# --- JSON æ ¡éªŒé€»è¾‘ ---
# æ¯æ¬¡è„šæœ¬è¿è¡Œæ—¶éƒ½é‡æ–°æ ¡éªŒä¸Šä¼ çš„æ–‡ä»¶çŠ¶æ€
mapping_validation_placeholder = st.empty() # ç”¨äºæ˜¾ç¤ºæ ¡éªŒç»“æœæ¶ˆæ¯
temp_mapping_data = None
if file_mapping is not None:
    try:
        # é‡ç½®æ–‡ä»¶è¯»å–æŒ‡é’ˆ
        file_mapping.seek(0)
        # å°è¯•è§£æ JSON
        temp_mapping_data = json.load(file_mapping)
        # åŸºæœ¬ç»“æ„æ£€æŸ¥ (ç¡®ä¿é¡¶å±‚æ˜¯å¯¹è±¡ï¼Œä¸”åŒ…å« 'field_mappings' åˆ—è¡¨)
        if isinstance(temp_mapping_data, dict) and isinstance(temp_mapping_data.get('field_mappings'), list):
            # åªæœ‰å½“æ–°ä¸Šä¼ çš„æ–‡ä»¶æœ‰æ•ˆæ—¶æ‰æ›´æ–° session_state
            st.session_state.mapping_data = temp_mapping_data
            st.session_state.mapping_valid = True
            mapping_validation_placeholder.success("âœ… æ˜ å°„æ–‡ä»¶ JSON æœ‰æ•ˆã€‚")
        else:
            st.session_state.mapping_valid = False # æ ‡è®°ä¸ºæ— æ•ˆï¼Œä½†ä¸æ¸…é™¤å¯èƒ½å­˜åœ¨çš„æ—§æœ‰æ•ˆæ•°æ®
            mapping_validation_placeholder.error("âŒ JSON æ–‡ä»¶é¡¶å±‚ç»“æ„é”™è¯¯ï¼šéœ€è¦åŒ…å« 'field_mappings' åˆ—è¡¨ã€‚")
            # å¯é€‰ï¼šæ¸…é™¤æ—§æ•°æ® st.session_state.mapping_data = None

    except json.JSONDecodeError as e:
        st.session_state.mapping_valid = False
        mapping_validation_placeholder.error(f"âŒ æ˜ å°„æ–‡ä»¶ JSON è¯­æ³•é”™è¯¯ï¼š\nåœ¨è¡Œ {e.lineno} åˆ— {e.colno} é™„è¿‘: {e.msg}")
        # å¯é€‰ï¼šæ¸…é™¤æ—§æ•°æ® st.session_state.mapping_data = None
    except Exception as e: # æ•è·å…¶ä»–å¯èƒ½çš„è¯»å–é”™è¯¯
        st.session_state.mapping_valid = False
        mapping_validation_placeholder.error(f"âŒ è¯»å–æˆ–è§£ææ˜ å°„æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        # å¯é€‰ï¼šæ¸…é™¤æ—§æ•°æ® st.session_state.mapping_data = None
else:
    # å¦‚æœ file_mapping æ§ä»¶ä¸­æ²¡æœ‰æ–‡ä»¶ï¼ˆä¾‹å¦‚ç”¨æˆ·æ¸…é™¤äº†ä¸Šä¼ ï¼‰ï¼Œä¹Ÿåº”æ›´æ–°çŠ¶æ€
    # å¦‚æœå¸Œæœ›ä¿ç•™ä¸Šæ¬¡æœ‰æ•ˆä¸Šä¼ çš„æ•°æ®ï¼Œå¯ä»¥æ³¨é‡Šæ‰ä¸‹é¢ä¸¤è¡Œ
    # st.session_state.mapping_data = None
    st.session_state.mapping_valid = None # è®¾ä¸º None è¡¨ç¤ºæœªä¸Šä¼ çŠ¶æ€
# --- ç»“æŸ JSON æ ¡éªŒ ---

# ä» session_state è·å–æ•°æ®ï¼Œå¦‚æœæ— æ•ˆæˆ–ä¸º None åˆ™ç”¨ç©ºå­—å…¸
mapping_data_from_state = st.session_state.get('mapping_data') or {}
field_mappings = mapping_data_from_state.get('field_mappings', [])

# --- ç¡®ä¿ template_fields å’Œ sample_source_fields åœ¨æ­¤å¤„è¢«æ— æ¡ä»¶åˆå§‹åŒ– ---
template_fields = []
sample_source_fields = set()
# --- ç»“æŸæ— æ¡ä»¶åˆå§‹åŒ– ---

# æ¨¡æ¿å­—æ®µåé¢„å–
if file_template:
    try:
        file_template.seek(0)
        template_df_header = pd.read_excel(file_template, skiprows=2, nrows=1)
        template_fields = template_df_header.columns.tolist()
    except Exception as e:
        st.warning(f"æ¨¡æ¿å­—æ®µè¯»å–å¤±è´¥ï¼š{e}")

# æºæ•°æ®å­—æ®µç¤ºä¾‹æ”¶é›†
if source_files:
    try:
        uploaded_source_file = source_files[0]
        uploaded_source_file.seek(0)
        source_preview = pd.read_excel(uploaded_source_file, nrows=10, header=None)
        # ä¿®å¤æ‹¬å·å’Œé€»è¾‘ï¼šæŸ¥æ‰¾åŒ…å«'å§“å'æˆ–'äººå‘˜å§“å'çš„è¡Œ
        header_row = next((i for i, row in source_preview.iterrows() if any(("å§“å" in str(cell)) or ("äººå‘˜å§“å" in str(cell)) for cell in row.astype(str))), None)
        if header_row is not None:
            # é‡ç½®æŒ‡é’ˆï¼Œè¯»å–æ­£ç¡®çš„è¡¨å¤´è¡Œ
            uploaded_source_file.seek(0)
            df_source_cols = pd.read_excel(uploaded_source_file, skiprows=header_row, nrows=0).columns.tolist() # nrows=0 ä¹Ÿå¯ä»¥è¯»è¡¨å¤´
            sample_source_fields = set(df_source_cols)
        else:
            st.warning("æ— æ³•åœ¨ç¬¬ä¸€ä¸ªæºæ–‡ä»¶ä¸­è‡ªåŠ¨æ£€æµ‹è¡¨å¤´è¡Œä»¥è·å–ç¤ºä¾‹å­—æ®µã€‚")
    except Exception as e:
        st.warning(f"è¯»å–æºæ•°æ®ç¤ºä¾‹å­—æ®µæ—¶å‡ºé”™: {e}")

# --- è§„åˆ™åŒ¹é…è®¾ç½® --- #
st.markdown("<p class='simple-subheader'>ğŸ”€ å­—æ®µåŒ¹é…å…³ç³»è®¾ç½®</p>", unsafe_allow_html=True)
# åªä¿ç•™ä¸€ä¸ªé€‰æ‹©æ¡†ï¼Œå› ä¸ºæºæ–‡ä»¶å’Œè§„åˆ™ä½¿ç”¨ç›¸åŒå­—æ®µå
# ä½¿ç”¨ sample_source_fields (ç¡®ä¿å®ƒå·²å®šä¹‰å¹¶å¯èƒ½æ˜¯ set)
source_cols_list = sorted(list(sample_source_fields)) if sample_source_fields else []
identity_column_name_select = st.selectbox(
    "é€‰æ‹©ç”¨äºåŒ¹é…è§„åˆ™çš„å­—æ®µå", # ä¿®æ”¹æ ‡ç­¾
    options=source_cols_list,
    index=source_cols_list.index("äººå‘˜èº«ä»½") if "äººå‘˜èº«ä»½" in source_cols_list else (source_cols_list.index("å²—ä½ç±»åˆ«") if "å²—ä½ç±»åˆ«" in source_cols_list else 0), # å°è¯•é»˜è®¤ äººå‘˜èº«ä»½ æˆ– å²—ä½ç±»åˆ«
    help="é€‰æ‹©æºæ–‡ä»¶å’ŒJSONè§„åˆ™ä¸­éƒ½ä½¿ç”¨çš„é‚£ä¸ªå­—æ®µåè¿›è¡ŒåŒ¹é…ï¼ˆå¦‚ äººå‘˜èº«ä»½, å²—ä½ç±»åˆ«ï¼‰" # ä¿®æ”¹å¸®åŠ©æ–‡æœ¬
)
# --- ç»“æŸè§„åˆ™åŒ¹é…è®¾ç½® --- #

# åªæœ‰å½“æ˜ å°„æ–‡ä»¶æœ‰æ•ˆæ—¶æ‰æ˜¾ç¤ºç¼–è¾‘å’Œå¯è§†åŒ–åŒºåŸŸ
if st.session_state.get('mapping_valid') is True:
    with st.expander("ğŸ“‹ æ˜ å°„è§„åˆ™ç¼–è¾‘ä¸å¯è§†åŒ–ï¼ˆæ”¯æŒæ–°å¢/æ ¡éªŒ/ä¸‹è½½ï¼‰", expanded=False):
        # å¯è§†åŒ–å­—æ®µæ˜ å°„ç»Ÿè®¡
        field_count = {"æœ‰æ•ˆæ˜ å°„": 0, "æºå­—æ®µç¼ºå¤±": 0, "ç›®æ ‡å­—æ®µç¼ºå¤±": 0}
        missing_source_details = [] # ç”¨äºå­˜å‚¨ç¼ºå¤±æºå­—æ®µçš„è¯¦ç»†ä¿¡æ¯
        missing_target_details = [] # ç”¨äºå­˜å‚¨ç¼ºå¤±ç›®æ ‡å­—æ®µçš„è¯¦ç»†ä¿¡æ¯

        # ç¡®ä¿ current_sample_source_fields åœ¨è¿™é‡Œå¯ç”¨
        current_sample_source_fields = sample_source_fields

        for rule in field_mappings:
            # è·å–å½“å‰è§„åˆ™çš„æ ‡è¯†ç¬¦ï¼Œç”¨äºæ—¥å¿—/é”™è¯¯ä¿¡æ¯
            # ä½¿ç”¨ç”¨æˆ·åœ¨ selectbox ä¸­é€‰æ‹©çš„å­—æ®µå
            rule_identity_value = rule.get(identity_column_name_select, "æœªçŸ¥è§„åˆ™æ ‡è¯†")

            for mapping in rule.get("mappings", []):
                src = mapping.get("source_field", "")
                tgt = mapping.get("target_field", "")

                # åªå¯¹ç®€å•æ˜ å°„è¿›è¡Œæº/ç›®æ ‡å­—æ®µæ ¡éªŒ
                if "source_field" in mapping:
                    is_valid = False # æ ‡è®°å½“å‰æ˜ å°„æ˜¯å¦æœ‰æ•ˆ
                    # æ£€æŸ¥æºå­—æ®µæ˜¯å¦å­˜åœ¨
                    if src not in current_sample_source_fields:
                        field_count["æºå­—æ®µç¼ºå¤±"] += 1
                        missing_source_details.append({
                            "rule_id": rule_identity_value,
                            "source": src,
                            "target": tgt
                        })
                    # å¦‚æœæºå­—æ®µå­˜åœ¨ï¼Œå†æ£€æŸ¥ç›®æ ‡å­—æ®µ (å¦‚æœæ¨¡æ¿å­˜åœ¨)
                    else:
                        # æ£€æŸ¥ç›®æ ‡å­—æ®µæ˜¯å¦åœ¨æ¨¡æ¿ä¸­ (ä»…å½“ template_fields éç©ºæ—¶)
                        if template_fields and (tgt not in template_fields):
                            field_count["ç›®æ ‡å­—æ®µç¼ºå¤±"] += 1
                            missing_target_details.append({
                                "rule_id": rule_identity_value,
                                "source": src,
                                "target": tgt
                            })
                        else:
                             # æºå­—æ®µå­˜åœ¨ï¼Œä¸”(æ— æ¨¡æ¿ æˆ– ç›®æ ‡å­—æ®µåœ¨æ¨¡æ¿ä¸­)
                             field_count["æœ‰æ•ˆæ˜ å°„"] += 1
                             is_valid = True
                    # (æ³¨æ„: å¤æ‚æ˜ å°„ ("source_fields") ä¸åœ¨æ­¤å¤„æ ¡éªŒæº/ç›®æ ‡å­—æ®µæ˜¯å¦å­˜åœ¨)

        # æ¡å½¢å›¾å±•ç¤ºæ˜ å°„æ ¡éªŒç»“æœ
        st.markdown("#### æ˜ å°„æ ¡éªŒç»Ÿè®¡å›¾")
        try:
            fig, ax = plt.subplots()
            bars = ax.bar(field_count.keys(), field_count.values(), color=["green", "orange", "red"])
            ax.bar_label(bars) # åœ¨æ¡å½¢å›¾ä¸Šæ˜¾ç¤ºæ•°å€¼
            ax.set_title("å­—æ®µæ˜ å°„çŠ¶æ€ç»Ÿè®¡")
            st.pyplot(fig)
        except Exception as plot_err:
            st.error(f"ç»˜åˆ¶å›¾è¡¨æ—¶å‡ºé”™: {plot_err}")

        # --- æ˜¾ç¤ºç¼ºå¤±å­—æ®µè¯¦æƒ… --- #
        st.markdown("--- impunity") # åˆ†éš”çº¿
        if missing_source_details:
            st.error("**æºå­—æ®µç¼ºå¤±è¯¦æƒ… (è¯·æ£€æŸ¥æºæ–‡ä»¶æˆ–æ˜ å°„è§„åˆ™):**")
            for detail in missing_source_details:
                st.markdown(f"- è§„åˆ™ **'{detail['rule_id']}'**: æºå­—æ®µ `'{detail['source']}'` (æ˜ å°„åˆ° `'{detail['target']}'`) åœ¨ç¤ºä¾‹æºæ–‡ä»¶ä¸­æœªæ‰¾åˆ°ã€‚")

        if missing_target_details:
            st.warning("**ç›®æ ‡å­—æ®µç¼ºå¤±è¯¦æƒ… (ä¸æ¨¡æ¿æ–‡ä»¶å¯¹æ¯”):**")
            for detail in missing_target_details:
                st.markdown(f"- è§„åˆ™ **'{detail['rule_id']}'**: ç›®æ ‡å­—æ®µ `'{detail['target']}'` (æ¥è‡ª `'{detail['source']}'`) åœ¨æ¨¡æ¿æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ã€‚")
        # --- ç»“æŸè¯¦æƒ…æ˜¾ç¤º --- #

        # æ˜ å°„ç¼–è¾‘
        for i, rule in enumerate(field_mappings):
            st.markdown(f"**äººå‘˜èº«ä»½ï¼š{rule.get('äººå‘˜èº«ä»½', '')} | ç¼–åˆ¶ï¼š{rule.get('ç¼–åˆ¶', '')}**")
            for j, mapping in enumerate(rule.get("mappings", [])):
                if "source_field" in mapping:
                    col1, col2 = st.columns(2)
                    with col1:
                        mapping["source_field"] = st.text_input(f"æºå­—æ®µ #{i}-{j}", mapping.get("source_field", ""), key=f"src_{i}_{j}")
                    with col2:
                        mapping["target_field"] = st.text_input(f"ç›®æ ‡å­—æ®µ #{i}-{j}", mapping.get("target_field", ""), key=f"tgt_{i}_{j}_simple")
                elif "source_fields" in mapping:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.markdown(f"**è®¡ç®—è§„åˆ™ #{i}-{j}**")
                        st.caption(f"æºå­—æ®µç»„: `{', '.join(mapping.get('source_fields', []))}`")
                        st.caption(f"è®¡ç®—æ–¹å¼: `{mapping.get('calculation', '')}`")
                    with col2:
                         mapping["target_field"] = st.text_input(f"ç›®æ ‡å­—æ®µ #{i}-{j}", mapping.get("target_field", ""), key=f"tgt_{i}_{j}_complex")
                else:
                    st.warning(f"è§„åˆ™ {i}-{j} æ ¼å¼æ— æ³•è¯†åˆ«: {mapping}")

        # --- æ–°å¢æ˜ å°„è§„åˆ™è¡¨å• (ç§»é™¤å†…å±‚ Expander) ---
        st.markdown("--- impunity") # æ·»åŠ åˆ†éš”çº¿
        st.markdown("**â• æ·»åŠ æ–°çš„äººå‘˜èº«ä»½æ˜ å°„**") # ä½¿ç”¨ markdown ä½œä¸ºæ ‡é¢˜
        # åå‘ç¼©è¿›ä»¥ä¸‹å†…å®¹
        new_identity = st.text_input("äººå‘˜èº«ä»½", key="new_identity_inp") # é¿å… key å†²çª
        new_bianzhi = st.text_input("ç¼–åˆ¶", key="new_bianzhi_inp")
        new_source = st.text_input("æºå­—æ®µå", key="new_source_inp")
        new_target = st.text_input("ç›®æ ‡å­—æ®µå", key="new_target_inp")
        if st.button("æ·»åŠ æ˜ å°„è§„åˆ™", key="add_mapping_btn"):
            # æŸ¥æ‰¾äººå‘˜èº«ä»½é”®ï¼Œéœ€è¦è€ƒè™‘ç”¨æˆ·é€‰æ‹©çš„ rule_identity_key_select
            # æš‚æ—¶ç¡¬ç¼–ç æ£€æŸ¥ 'äººå‘˜èº«ä»½'ï¼Œä½†ç†æƒ³æƒ…å†µåº”ä½¿ç”¨é€‰æ‹©çš„ key
            match_key = "äººå‘˜èº«ä»½" # æˆ–è€… rule_identity_key_select (éœ€è¦ä»å¤–éƒ¨ä¼ å…¥æˆ–session stateè·å–)
            if not new_identity: # å‡è®¾æ–°è§„åˆ™åŸºäº"äººå‘˜èº«ä»½"æ·»åŠ 
                 st.warning("è¯·è¾“å…¥è¦æ·»åŠ è§„åˆ™çš„'äººå‘˜èº«ä»½'å€¼", icon="âš ï¸")
            elif not new_source or not new_target:
                 st.warning("è¯·è¾“å…¥æºå­—æ®µåå’Œç›®æ ‡å­—æ®µå", icon="âš ï¸")
            else:
                new_rule = next((r for r in field_mappings if r.get(match_key) == new_identity), None)
                if not new_rule:
                    new_rule = {match_key: new_identity, "ç¼–åˆ¶": new_bianzhi, "mappings": []}
                    # æ³¨æ„ï¼šç›´æ¥ä¿®æ”¹ field_mappings å¯èƒ½åœ¨ rerun åä¸¢å¤±ï¼Œéœ€è¦æ›´æ–° session_state
                    field_mappings.append(new_rule)
                    # æ›´æ–° session state (é‡è¦!)
                    if st.session_state.mapping_data:
                         st.session_state.mapping_data['field_mappings'] = field_mappings
                new_rule["mappings"].append({"source_field": new_source, "target_field": new_target})
                st.success("âœ… æ–°æ˜ å°„å·²æ·»åŠ  (è¯·è®°å¾—ä¸‹è½½ä¿å­˜)")
                st.experimental_rerun() # æ·»åŠ æ˜ å°„åéœ€è¦é‡æ–°è¿è¡Œä»¥æ›´æ–°æ˜¾ç¤º
        # --- ç»“æŸæ–°å¢è¡¨å• ---

        # ä¸‹è½½ä¿å­˜
        edited_json_for_download = json.dumps({"field_mappings": field_mappings}, ensure_ascii=False, indent=2)
        st.download_button("ğŸ“¥ ä¸‹è½½å½“å‰æ˜ å°„è§„åˆ™ JSON", edited_json_for_download, file_name="å­—æ®µæ˜ å°„è§„åˆ™_ç¼–è¾‘ç‰ˆ.json", mime="application/json")

        if st.button("ğŸ’¾ ä¿å­˜æ˜ å°„è§„åˆ™åˆ°æœåŠ¡å™¨ï¼ˆæ¨¡æ‹Ÿï¼‰"):
            save_path = "./æ˜ å°„è§„åˆ™_ä¿å­˜å¤‡ä»½.json"
            try:
                with open(save_path, "w", encoding="utf-8") as f:
                    f.write(edited_json_for_download)
                st.success(f"å·²ä¿å­˜åˆ°ï¼š{save_path}")
            except Exception as save_err:
                st.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {save_err}")

# --- å¤„ç†è§¦å‘åŒºåŸŸ ---
st.markdown("---") # åˆ†éš”çº¿

if st.button("ğŸš€ å¼€å§‹å¤„ç†æ•°æ®", type="primary"):
    # æ¸…ç©ºæ—§æ—¥å¿—å¹¶è®°å½•å¼€å§‹
    st.session_state.log_messages = []
    log("å¼€å§‹å¤„ç†æµç¨‹...", "INFO")

    # 1. è¾“å…¥æ ¡éªŒ
    valid_inputs = True
    if not source_files:
        log("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä¸ªæºæ•°æ®å·¥èµ„è¡¨ï¼", "ERROR")
        valid_inputs = False
    if not file_deductions:
        log("è¯·ä¸Šä¼ æ‰£æ¬¾é¡¹è¡¨ï¼", "ERROR")
        valid_inputs = False
    if not st.session_state.get('mapping_valid', False):
        log("å­—æ®µæ˜ å°„æ–‡ä»¶æ— æ•ˆæˆ–æœªä¸Šä¼ ï¼", "ERROR")
        valid_inputs = False
    if not identity_column_name_select:
        log("è¯·é€‰æ‹©ç”¨äºåŒ¹é…è§„åˆ™çš„å­—æ®µåï¼", "ERROR")
        valid_inputs = False

    if valid_inputs:
        # 2. å‡†å¤‡æ•°æ®
        deduction_df = None
        current_field_mappings = st.session_state.get('mapping_data', {}).get('field_mappings', [])
        selected_deduction_fields = [] # åˆå§‹åŒ–

        try:
            log("è¯»å–æ‰£æ¬¾æ•°æ®...", "INFO")
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_deduct:
                file_deductions.seek(0)
                tmp_deduct.write(file_deductions.getvalue())
                tmp_deduct_path = tmp_deduct.name
            try:
                deduction_df = pd.read_excel(tmp_deduct_path)
            finally:
                os.unlink(tmp_deduct_path)

            # æ ¡éªŒæ‰£æ¬¾è¡¨å§“ååˆ—
            key_col_found = False
            name_columns = ["å§“å", "äººå‘˜å§“å"]
            actual_name_col = None
            for key_col in name_columns:
                if key_col in deduction_df.columns:
                    key_col_found = True
                    actual_name_col = key_col # è®°å½•æ‰¾åˆ°çš„å§“ååˆ—
                    break
            if not key_col_found:
                log(f"æ‰£æ¬¾è¡¨å¿…é¡»åŒ…å« 'å§“å' æˆ– 'äººå‘˜å§“å' åˆ—ï¼", "ERROR")
                st.stop()
            else:
                log(f"æ‰£æ¬¾æ•°æ®è¯»å–æˆåŠŸï¼Œæ‰¾åˆ°é”®åˆ—: '{actual_name_col}'ã€‚", "INFO")

            # è‡ªåŠ¨ç¡®å®šæ‰£æ¬¾å­—æ®µåˆ—è¡¨
            all_deduction_cols = deduction_df.columns.tolist()
            selected_deduction_fields = [col for col in all_deduction_cols if col != actual_name_col]
            log(f"è‡ªåŠ¨è¯†åˆ«ç”¨äºåˆå¹¶çš„æ‰£æ¬¾å­—æ®µ (å…± {len(selected_deduction_fields)} ä¸ª): {selected_deduction_fields}", "INFO")
            if not selected_deduction_fields:
                 log("è­¦å‘Šï¼šæ‰£æ¬¾è¡¨ä¸­é™¤äº†å§“ååˆ—å¤–æœªæ‰¾åˆ°å…¶ä»–å­—æ®µã€‚", "WARNING")

            # 3. å¤„ç†æ¯ä¸ªæºæ–‡ä»¶
            all_results = []
            has_error = False
            log(f"å¼€å§‹é€ä¸ªå¤„ç† {len(source_files)} ä¸ªæºæ–‡ä»¶... (ä½¿ç”¨ '{identity_column_name_select}' å­—æ®µåŒ¹é…)", "INFO")
            with st.spinner(f"æ­£åœ¨å¤„ç† {len(source_files)} ä¸ªæºæ–‡ä»¶..."):
                for i, uploaded_file in enumerate(source_files):
                    log(f"[{i+1}/{len(source_files)}] å¤„ç†æ–‡ä»¶: {uploaded_file.name}", "INFO")
                    tmp_source_path = None
                    try:
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_source:
                            tmp_source.write(uploaded_file.getvalue())
                            tmp_source_path = tmp_source.name

                        # æ·»åŠ è°ƒç”¨ process_sheet çš„æ—¥å¿—
                        log(f"  -> è°ƒç”¨æ ¸å¿ƒå¤„ç†å‡½æ•° process_sheet...", "INFO")
                        result_df = process_sheet(
                            tmp_source_path,
                            deduction_df,
                            current_field_mappings,
                            selected_deduction_fields,
                            identity_column_name_select,
                            identity_column_name_select
                         )
                        log(f"  <- process_sheet è¿”å›ï¼Œç»“æœè¡Œæ•°: {len(result_df) if result_df is not None else 'None'}", "INFO")
                        if result_df is not None and not result_df.empty:
                             all_results.append(result_df)
                             log(f"[{i+1}/{len(source_files)}] æ–‡ä»¶ {uploaded_file.name} å¤„ç†æˆåŠŸã€‚", "SUCCESS")
                        else:
                             log(f"[{i+1}/{len(source_files)}] æ–‡ä»¶ {uploaded_file.name} æœªè¿”å›æœ‰æ•ˆæ•°æ® (å¯èƒ½æ— åŒ¹é…è¡Œæˆ–å¤„ç†é”™è¯¯)ã€‚", "WARNING")

                    except ValueError as ve: # æ•è· process_sheet è¿”å›çš„ç‰¹å®šé”™è¯¯ï¼Ÿè¿˜æ˜¯å†…éƒ¨å¤„ç†ï¼Ÿ
                        # å‡è®¾ process_sheet å†…éƒ¨å·²æ‰“å°é”™è¯¯ï¼Œè¿™é‡Œåªè®°å½•å¤±è´¥
                        log(f"[{i+1}/{len(source_files)}] æ–‡ä»¶ {uploaded_file.name} å¤„ç†å¤±è´¥ã€‚", "ERROR")
                        has_error = True
                    except Exception as e:
                        log(f"[{i+1}/{len(source_files)}] å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯: {e}", "ERROR")
                        has_error = True
                    finally:
                        if tmp_source_path and os.path.exists(tmp_source_path):
                           os.unlink(tmp_source_path)
                    if has_error:
                         log(f"å› å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‘ç”Ÿé”™è¯¯ï¼Œå¤„ç†ä¸­æ­¢ã€‚", "ERROR")
                         break # ä¿æŒä¸­æ­¢é€»è¾‘

            # 4. åˆå¹¶ä¸æ ¼å¼åŒ–
            if not has_error and all_results:
                log("æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼Œå¼€å§‹åˆå¹¶ {len(all_results)} ä¸ªç»“æœ...", "INFO")
                with st.spinner("åˆå¹¶ç»“æœå¹¶æ ¼å¼åŒ–è¾“å‡º..."):
                    tmp_processed_path = None
                    output_path = None
                    try:
                        combined_df = pd.concat(all_results, ignore_index=True)
                        log("ç»“æœåˆå¹¶å®Œæˆï¼Œæ€»è¡Œæ•°: {len(combined_df)}", "INFO")

                        if file_template and template_fields:
                            # æ¢å¤ä¸ºä¸¥æ ¼æŒ‰æ¨¡æ¿ reindexï¼Œä¸¢å¼ƒä¸åœ¨æ¨¡æ¿ä¸­çš„åˆ—
                            log(f"æ ¹æ®æ¨¡æ¿æ–‡ä»¶çš„ {len(template_fields)} ä¸ªå­—æ®µä¸¥æ ¼ç­›é€‰å’Œæ’åºè¾“å‡ºåˆ—...", "INFO")
                            combined_df = combined_df.reindex(columns=template_fields)
                            # æ³¨æ„ï¼šå¦‚æœ template_fields åŒ…å« combined_df ä¸­æ²¡æœ‰çš„åˆ—ï¼Œreindex ä¼šæ·»åŠ å®ƒä»¬å¹¶å¡«å…… NaN
                        else:
                             log("æœªæä¾›æ¨¡æ¿æ–‡ä»¶æˆ–è¯»å–å¤±è´¥ï¼ŒæŒ‰åŸå§‹å¤„ç†é¡ºåºè¾“å‡ºæ‰€æœ‰åˆ—ã€‚", "INFO")

                        log("ä¿å­˜å¤„ç†ç»“æœåˆ°ä¸´æ—¶æ–‡ä»¶...", "INFO")
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_processed:
                            combined_df.to_excel(tmp_processed.name, index=False)
                            tmp_processed_path = tmp_processed.name

                        output_filename = f"{unit_name}_{salary_date.strftime('%Y%m')}_å·¥èµ„å‘æ”¾è¡¨_å·²å¤„ç†.xlsx"
                        output_dir = tempfile.mkdtemp()
                        output_path = os.path.join(output_dir, output_filename)

                        log("å¼€å§‹æ ¼å¼åŒ–è¾“å‡ºæ–‡ä»¶...", "INFO")
                        format_excel_with_styles(tmp_processed_path, output_path, salary_date.year, salary_date.month)
                        log("æ–‡ä»¶æ ¼å¼åŒ–å®Œæˆã€‚", "SUCCESS")

                        # 5. æä¾›ä¸‹è½½
                        # st.success(f"ğŸ‰ å¤„ç†å®Œæˆï¼...") # ç”± log æ›¿ä»£
                        log(f"å¤„ç†æˆåŠŸå®Œæˆï¼æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆï¼š{output_filename}", "SUCCESS")
                        with open(output_path, "rb") as fp:
                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½æœ€ç»ˆæŠ¥å‘Š",
                                data=fp,
                                file_name=output_filename,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                key="download_report"
                            )

                    except Exception as e:
                        log(f"åˆå¹¶æˆ–æ ¼å¼åŒ– Excel æ–‡ä»¶æ—¶å‡ºé”™: {e}", "ERROR")
                        has_error = True # ç¡®ä¿æ ‡è®°é”™è¯¯
                    finally:
                        if tmp_processed_path and os.path.exists(tmp_processed_path):
                            os.unlink(tmp_processed_path)

            elif not all_results and not has_error:
                 log("æœªç”Ÿæˆä»»ä½•æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æºæ–‡ä»¶å†…å®¹å’Œæ˜ å°„è§„åˆ™ã€‚", "WARNING")
            elif has_error:
                log("å¤„ç†å› å‘ç”Ÿé”™è¯¯è€Œä¸­æ­¢ã€‚", "ERROR")

        except Exception as e:
            log(f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿæ— æ³•æ¢å¤çš„ä¸¥é‡é”™è¯¯: {e}", "ERROR")
            # ç¡®ä¿æ¸…ç†å¯èƒ½é—ç•™çš„ä¸´æ—¶æ–‡ä»¶
            if 'tmp_deduct_path' in locals() and os.path.exists(tmp_deduct_path):
                os.unlink(tmp_deduct_path)
            if 'tmp_source_path' in locals() and os.path.exists(tmp_source_path):
                os.unlink(tmp_source_path)
            if 'tmp_processed_path' in locals() and os.path.exists(tmp_processed_path):
                os.unlink(tmp_processed_path)

    else:
        log("è¾“å…¥æ ¡éªŒå¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šä¼ çš„æ–‡ä»¶å’Œé…ç½®ã€‚", "ERROR")

# å¯ä»¥æ·»åŠ é¡µè„šç­‰ä¿¡æ¯
st.markdown("---")
st.caption("Â© æˆéƒ½é«˜æ–°åŒºè´¢æ”¿é‡‘èå±€")
